<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Clase 9: Usos de APIs</title>
    <meta charset="utf-8" />
    <meta name="author" content=" Cristi√°n Ayala  Director DESUC" />
    <script src="libs/header-attrs-2.14/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/default-fonts.css" rel="stylesheet" />
    <link rel="stylesheet" href="../gentle-r.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

.title[
# Clase 9: Usos de APIs
]
.subtitle[
## Web Scraping y acceso a datos desde la web con R
]
.author[
### <br>Cristi√°n Ayala<br> Director DESUC
]
.date[
### <a href="https://github.com/caayala">github.com/caayala</a>
]

---





## Motivaci√≥n

- Utilizar *puertas* provistas por servicios web para acceder a su informaci√≥n.

  - Wikipedia, Spotify, Twitter.

- Revisar paquetes ya desarrollados para acceder a servicios populares.

---

## Paquetes para la clase de hoy

Grupo de paquetes interrelacionados:

- [WikipediR](https://github.com/Ironholds/WikipediR/): Empaqueta la API de MediaWiki para bajar datos de Wikipedia.

- [spotifyr](https://www.rcharlie.com/spotifyr/): Empaqueta la API de Spotify para bajar datos.

- [rtweet](https://docs.ropensci.org/rtweet/): Permite interactuar con la API de Twitter.

- [academictwitteR](https://github.com/cjbarrie/academictwitteR): Acceso a la APIv2 de Twitter para su producto acad√©mico.


---

## Wikipedia

El software sobre el que est√° montada Wikipedia ---[MediaWiki](https://en.wikipedia.org/wiki/MediaWiki#Application_programming_interface)--- cuenta con una API 
para acceder al contenido almacenado en sus bases de datos.

- MediaWiki API: [P√°gina principal](https://www.mediawiki.org/wiki/API:Main_page)

Veamos la documentaci√≥n y como crear llamados en la [sandbox](https://www.mediawiki.org/wiki/Special:ApiSandbox) disponible

---

## Wikipedia: API

Revisemos la [API de Wikipedia](https://www.mediawiki.org/wiki/API:Main_page). 

- Revisi√≥n de acciones disponibles.
  - [`Search`](https://www.mediawiki.org/wiki/API:Search): Buscar p√°ginas.

  - [`Parse`](https://www.mediawiki.org/wiki/API:Parsing_wikitext): Obtener contenido de una p√°gina.
  
  - [`Query`](https://www.mediawiki.org/wiki/API:Query): Obtener informaci√≥n de p√°ginas.

Captura de p√°gina sobre *web scraping* en espa√±ol.


---

## Wikipedia: API buscar API:Search

Construcci√≥n de GET para la acci√≥n [`Search`](https://www.mediawiki.org/wiki/API:Search).

.font70[

```r
resp &lt;- GET('https://es.wikipedia.org/w/api.php',
            query = list(action = 'query',
                         list = 'search',
                         srsearch = 'web scraping',
                         srlimit = 5,
                         format = 'json'),
            add_headers('Accept-Encoding' = 'gzip'))

df &lt;- content(resp, as = 'text') |&gt; 
  jsonlite::fromJSON()

df$query$search |&gt; as_tibble()
```

```
## # A tibble: 5 √ó 7
##      ns title               pageid  size wordcount snippet             timestamp
##   &lt;int&gt; &lt;chr&gt;                &lt;int&gt; &lt;int&gt;     &lt;int&gt; &lt;chr&gt;               &lt;chr&gt;    
## 1     0 Web scraping       5544299 11174      1454 "&lt;span class=\"sea‚Ä¶ 2022-05-‚Ä¶
## 2     0 Screen scraping    1194524  1116       153 "casos, es al cont‚Ä¶ 2019-07-‚Ä¶
## 3     0 Scrapy             9214341  2195       142 "por Scrapinghub L‚Ä¶ 2021-10-‚Ä¶
## 4     0 HtmlUnit           4481985  3644       309 "p√°ginas &lt;span cla‚Ä¶ 2019-08-‚Ä¶
## 5     0 WSO2 Mashup Server 4721686  8713       894 "sintaxis es id√©nt‚Ä¶ 2021-12-‚Ä¶
```
]


---

## Wikipedia: API contenido API:Parse 1

Obtenci√≥n del contenido de p√°gina. GET para la acci√≥n [`Parse`](https://www.mediawiki.org/wiki/API:Parsing_wikitext).


```r
resp &lt;- GET('https://es.wikipedia.org/w/api.php',
            query = list(action = 'parse',
                         page = 'Web scraping', # contenido de t√≠tulo de p√°gina
                         prop = 'text', # html de retorno
                         format = 'json'),
            add_headers('Accept-Encoding' = 'gzip'))

df &lt;- content(resp, as = 'text') |&gt; jsonlite::fromJSON()

str(df, 2)
```

```
## List of 1
##  $ parse:List of 3
##   ..$ title : chr "Web scraping"
##   ..$ pageid: int 5544299
##   ..$ text  :List of 1
```


---

## Wikipedia: API contenido API:Parse 2

El texto de contenido

.font40[

```r
df$parse$text$`*` |&gt; 
  read_html() |&gt; html_text() |&gt; 
  cat()
```

```
## Web scraping o raspado web, es una t√©cnica utilizada mediante programas de software para extraer informaci√≥n de sitios web.[1]‚Äã Usualmente, estos programas simulan la navegaci√≥n de un humano en la World Wide Web ya sea utilizando el protocolo HTTP manualmente, o incrustando un navegador en una aplicaci√≥n.
## El web scraping est√° muy relacionado con la indexaci√≥n de la web, la cual indexa la informaci√≥n de la web utilizando un robot y es una t√©cnica universal adoptada por la mayor√≠a de los motores de b√∫squeda. Sin embargo, el web scraping se enfoca m√°s en la transformaci√≥n de datos sin estructura en la web (como el formato HTML) en datos estructurados que pueden ser almacenados y analizados en una base de datos central, en una hoja de c√°lculo o en alguna otra fuente de almacenamiento. Alguno de los usos del web scraping son la comparaci√≥n de precios en tiendas, la monitorizaci√≥n de datos relacionados con el clima de cierta regi√≥n, la detecci√≥n de cambios en sitios webs y la integraci√≥n de datos en sitios webs. Tambi√©n es utilizado para obtener informaci√≥n relevante de un sitio a trav√©s de los rich snippets. 
## En los √∫ltimos a√±os el web scraping se ha convertido en una t√©cnica muy utilizada dentro del sector del posicionamiento web gracias a su capacidad de generar grandes cantidades de datos para crear contenidos de calidad.[2]‚Äã
## 
## √çndice
## 1 T√©cnicas
## 2 Cuestiones legales
## 3 Medidas para detener a los scrapers
## 4 Beneficios
## 5 Herramientas notables
## 6 V√©ase tambi√©n
## 7 Referencias
## 
## 
## T√©cnicas[editar]
## Web scraping es el proceso de recopilar informaci√≥n de forma autom√°tica de la Web. Es un campo con desarrollos activos, compartiendo un prop√≥sito en com√∫n con la visi√≥n de la Web sem√°ntica. Utiliza soluciones pr√°cticas basadas en tecnolog√≠as existentes que son com√∫nmente ad hoc. Existen distintos niveles de automatizaci√≥n que las existentes tecnolog√≠as de Web Scraping pueden brindar:
## 
## ¬´Copiar y pegar¬ª humano: algunas veces incluso las mejores t√©cnicas de web scraping no pueden reemplazar el examen manual de un humano, y a veces esta puede ser la √∫nica v√≠a de soluci√≥n cuando el sitio que tenemos en mente pone ciertas barreras para prevenir que se creen softwares para realizar tareas autom√°ticas en este.
## Uso de expresiones regulares: una posible v√≠a para extraer informaci√≥n de p√°ginas webs pueden ser las expresiones regulares, aunque com√∫nmente no se recomienda utilizarlas para parsear el formato HTML.
## Protocolo HTTP: p√°ginas webs est√°ticas y din√°micas pueden ser obtenidas haciendo peticiones HTTP al servidor remoto utilizando sockets, etc.
## Algoritmos de miner√≠a de datos: muchos sitios webs tienen grandes colecciones de p√°ginas generadas din√°micamente a partir de una base de datos. Datos de la misma categor√≠a aparecen usualmente en p√°ginas similares mediante un script o una plantilla. En la miner√≠a de datos, un programa detecta estas plantillas en un contexto espec√≠fico y extrae su contenido.
## Parsers de HTML: Algunos lenguajes, como XQuery y HTQL pueden ser utilizados para parsear documentos, recuperar y transformar el contenido de documentos HTML.
## Aplicaciones para web scraping: existen muchas aplicaciones disponibles que pueden ser utilizadas para personalizar soluciones de Web Scraping. Estas aplicaciones podr√≠an reconocer autom√°ticamente la estructura de cierta p√°gina o brindar una interfaz al usuario donde este pudiera seleccionar los campos que son de inter√©s dentro del documento. De esta forma no es necesario escribir manualmente c√≥digo para realizar estas tareas.
## Reconocimiento de informaci√≥n sem√°ntica: las p√°ginas que son analizadas podr√≠an incluir metadatos o cierta informaci√≥n sem√°ntica como anotaciones o comentarios, los cuales pueden ser usados com√∫nmente. Si estas anotaciones est√°n en las mismas p√°ginas, como sucede con los microformatos, estas podr√≠an ser de utilidad cuando parseamos el DOM del documento. En otro caso, las anotaciones, organizadas en una capa sem√°ntica, son almacenadas y manejadas de forma separada desde otras p√°ginas, por lo que los scrapers pueden recuperar estos esquemas y las instrucciones desde esta capa antes de analizar los documentos.[3]‚ÄãCuestiones legales[editar]
## El web scraping pudiera ir en contra de los t√©rminos de uso de algunos sitios webs. El cumplimiento de estos t√©rminos no est√° totalmente claro.[4]‚Äã Mientras que la duplicaci√≥n de expresiones originales puede ser en muchos casos ilegal, en Estados Unidos la corte dict√≥ en el caso Feist Publications v. Rural Telephone Service que la duplicaci√≥n de hechos es permitida. Las cortes de Estados Unidos en ciertas ocasiones han reconocido que ciertos usos de los scrapers no deber√≠an estar permitidos. Podr√≠a considerarse una computadora como una propiedad personal, y de esta forma el scraper estar√≠a entrando sin autorizaci√≥n en esta propiedad. En el caso m√°s conocido, eBay vs Bidder's Edge, la segunda empresa tuvo que parar de realizar peticiones autom√°ticas al sitio de eBay. En este caso, Bidder's Edge pujaba autom√°ticamente por ciertos productos en este sitio.
## Uno de las principales pruebas de scraping involucr√≥ a American Airlines y a una empresa llamada FareChase. American Airlines gan√≥ esta batalla, haciendo que FareChase parara de vender un software que le permit√≠a a los usuarios comparar tarifas en l√≠nea si el sitio de American Airlines era incluido. La aerol√≠nea dijo que las b√∫squedas de FareChase entraban sin autorizaci√≥n en los servidores cuando recopilaban la informaci√≥n p√∫blicamente disponible.
## Aunque las decisiones actualmente tomadas no son uniformes, es dif√≠cil ignorar que un patr√≥n est√° emergiendo, en el cual podemos ver que las cortes est√°n prepar√°ndose para proteger el contenido propietario en sitios webs comerciales, previendo de esta forma que este sea utilizado sin el consentimiento de los propietarios de los sitios. Sin embargo, el grado de protecci√≥n de estos contenidos a√∫n no est√° establecido, y depender√° del tipo de acceso realizado por los scrapers, de la cantidad de informaci√≥n recopilada y del grado en el que afecten estos factores al propietario del sitio web.
## 
## Medidas para detener a los scrapers[editar]
## El administrador de un sitio web puede utilizar varias t√©cnicas para detener o disminuir los pedidos de los scrapers. Algunas t√©cnicas incluyen:
## 
## A√±adir entradas al fichero robots.txt. Algunos bots pueden ser detenidos de esta forma. Hay personas que piensan que el bot de Google puede ser detenido as√≠, cosa que el propio buscador ha negado.
## Bloquear la direcci√≥n IP. Esto tambi√©n bloquear√° todos los accesos desde esa misma IP, por lo que los usuarios no podr√°n navegar por el sitio web si acceden desde esta.
## Deshabilitar cualquier interfaz de programaci√≥n de aplicaciones que el sitio web pudiera estar brindando.
## Los bots o scrapers algunas veces declaran quienes son, y gracias a esto pueden ser bloqueados. ¬´Googlebot¬ª es un ejemplo. Algunos scrapers no hacen lo que el bot de G., para que no se pueda distinguir entre un navegador com√∫n y ellos.
## Monitorear el exceso de tr√°fico proveniente de cierta IP.
## A√±adir un captcha u otro sistema de verificaci√≥n manual al sitio web. No se garantiza el completo bloqueo de los scrapers, pero mediante esta t√©cnica se dificulta el acceso de los mismos a los sitios webs.
## Servicios comerciales antibots: algunas empresas ofrecen servicios antibots y antiscraping.[5]‚Äã
## Incrementar el uso de JavaScript y AJAX. De esta forma es m√°s dif√≠cil para los scrapers simular las peticiones como si fueran un navegador com√∫n, aunque har√° que usuarios leg√≠timos dejen de poder ver la p√°gina.La mayor√≠a de estos m√©todos suponen una merma importante en la usabilidad del sitio web en cuesti√≥n y los beneficios pueden ser muy puntuales.
## 
## Beneficios[editar]
## Pese al planteamiento negativo de ciertos sectores, el rastreo autom√°tico y scraping son muy importantes para mantener la historia de Internet. Las iniciativas de archivado web se basan mayoritariamente en esta t√©cnica.
## 
## Herramientas notables[editar]
## 
## UIPath
## Apache Camel
## Automation Anywhere
## Convertigo
## cURL
## Data Toolbar
## Firebug
## Greasemonkey
## HtmlUnit
## Node.js
## HTTrack
## iMacros
## Aptana Jaxer
## nokogiri
## watir
## Wget
## WSO2 Mashup Server
## HtmlAgilityPack
## BeautifulSoup
## Scrapy
## V√©ase tambi√©n[editar]
## Miner√≠a de datos
## Mashup (aplicaci√≥n web h√≠brida)
## Spamdexing
## Corpus ling√º√≠stico
## Ara√±a web
## Metadato
## Screen scraping.Referencias[editar]
## ‚Üë  Mart√≠, Marq (8 de abril de 2016). ¬´¬øQu√© es el Web scraping? Introducci√≥n y herramientas¬ª (html). Sitelab Espa√±a. Archivado desde el original el 29 de julio de 2017. Consultado el 30 de marzo de 2020. ¬´El web scraping es una t√©cnica que sirve para extraer informaci√≥n de p√°ginas web de forma automatizada. Si traducimos del ingl√©s su significado vendr√≠a a significar algo as√≠ como ‚Äúescarbar una web‚Äù.¬ª¬† 
## 
## ‚Üë  Mart√≠, Marq (8 de abril de 2016). ¬´¬øQu√© es el Web scraping? Introducci√≥n y herramientas¬ª (html). Sitelab Espa√±a. Archivado desde el original el 29 de julio de 2017. Consultado el 30 de marzo de 2020. ¬´Para controlar la imagen y la visibilidad de nuestra marca en internet: a trav√©s de un scrapeo podemos automatizar la posici√≥n por la que varios art√≠culos de nuestra web se posicionan en Google o, por ejemplo, controlar la presencia del nombre de nuestra marca en determinados foros. Ejemplo: rastrear la posici√≥n en Google de todas las entradas de nuestro blog.¬ª¬† 
## 
## ‚Üë http://www.gooseeker.com/en/node/knowledgebase/freeformat
## 
## ‚Üë https://web.archive.org/web/20020308222536/http://www.chillingeffects.org/linking/faq.cgi#QID596
## 
## ‚Üë https://s3.us-west-2.amazonaws.com/research-papers-mynk/Breaking-Fraud-And-Bot-Detection-Solutions.pdf
## 
## 
## .mw-parser-output .mw-authority-control{margin-top:1.5em}.mw-parser-output .mw-authority-control .navbox hr:last-child{display:none}.mw-parser-output .mw-authority-control .navbox+.mw-mf-linked-projects{display:none}.mw-parser-output .mw-authority-control .mw-mf-linked-projects{display:flex;padding:0.5em;border:1px solid #c8ccd1;background-color:#eaecf0;color:#222222}.mw-parser-output .mw-authority-control .mw-mf-linked-projects ul li{margin-bottom:0}Control de autoridades
## Proyectos Wikimedia
##  Datos: Q665452
##  Datos: Q665452
```
]


---

## Wikipedia: API informaci√≥n API:Query 1

Informaci√≥n de varias p√°ginas. GET para la acci√≥n [`Query`](https://www.mediawiki.org/wiki/API:Query).


```r
resp &lt;- GET('https://es.wikipedia.org/w/api.php',
            query = list(action = 'query',
                         titles = 'Web scraping|Python', # Varios t√≠tulos a la ves.
                         prop = 'info|categories|iwlinks', # Informaci√≥n a obtener.
                         format = 'json'),
            add_headers('Accept-Encoding' = 'gzip'))

df &lt;- content(resp, as = 'text') |&gt; jsonlite::fromJSON()

str(df, 3)
```

```
## List of 2
##  $ continue:List of 2
##   ..$ clcontinue: chr "2330|Wikipedia:Art√≠culos_buenos_en_la_Wikipedia_en_√°rabe"
##   ..$ continue  : chr "||info|iwlinks"
##  $ query   :List of 1
##   ..$ pages:List of 2
##   .. ..$ 2330   :List of 12
##   .. ..$ 5544299:List of 11
```


---

## Wikipedia: API informaci√≥n API:Query 2

.font70[

```r
df$query$pages |&gt; 
  enframe() |&gt; unnest_wider(value)
```

```
## # A tibble: 2 √ó 13
##   name     pageid    ns title        contentmodel pagelanguage pagelanguagehtml‚Ä¶
##   &lt;chr&gt;     &lt;int&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;            
## 1 2330       2330     0 Python       wikitext     es           es               
## 2 5544299 5544299     0 Web scraping wikitext     es           es               
## # ‚Ä¶ with 6 more variables: pagelanguagedir &lt;chr&gt;, touched &lt;chr&gt;,
## #   lastrevid &lt;int&gt;, length &lt;int&gt;, categories &lt;list&gt;, iwlinks &lt;list&gt;
```
]


---

## Wikipedia: usando WikipediR 1

Lo mismo, pero m√°s f√°cil.

.pull-left.font70[
- `page_info`: informaci√≥n sobre una p√°gina espec√≠fica.

- `page_content`: contenido de una p√°gina espec√≠fica.

- `page_links`: links disponibles en una p√°gina espec√≠fica.



```r
library(WikipediR)

info_wiki &lt;- page_info(
  language = 'es', 
  project = 'wikipedia', 
  page = 'Web_scraping|Python') 
```
]

.pull-right.font70[

```r
str(info_wiki, 3)
```

```
## List of 2
##  $ batchcomplete: chr ""
##  $ query        :List of 2
##   ..$ normalized:List of 1
##   .. ..$ :List of 2
##   ..$ pages     :List of 2
##   .. ..$ 2330   :List of 17
##   .. ..$ 5544299:List of 17
##  - attr(*, "class")= chr "pageinfo"
```
]


---

## Wikipedia: usando WikipediR 2

Resultado de la b√∫squeda.

.font70[

```r
info_wiki$query$pages |&gt; 
  enframe() |&gt; unnest_wider(value)
```

```
## # A tibble: 2 √ó 18
##   name     pageid    ns title        contentmodel pagelanguage pagelanguagehtml‚Ä¶
##   &lt;chr&gt;     &lt;int&gt; &lt;int&gt; &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;        &lt;chr&gt;            
## 1 2330       2330     0 Python       wikitext     es           es               
## 2 5544299 5544299     0 Web scraping wikitext     es           es               
## # ‚Ä¶ with 11 more variables: pagelanguagedir &lt;chr&gt;, touched &lt;chr&gt;,
## #   lastrevid &lt;int&gt;, length &lt;int&gt;, protection &lt;lgl&gt;, restrictiontypes &lt;list&gt;,
## #   talkid &lt;int&gt;, fullurl &lt;chr&gt;, editurl &lt;chr&gt;, canonicalurl &lt;chr&gt;,
## #   displaytitle &lt;chr&gt;
```
]


---

## Wikipedia: usando WikipediR 3

Captura de p√°gina sobre *web scraping* en espa√±ol.

.font70[

```r
cont_wiki &lt;-  page_content(language = 'es', 
                           project = 'wikipedia', 
                           page_name = 'Web_scraping')

str(cont_wiki) # Una lisa parse con 4 elementos dentro
```

```
## List of 1
##  $ parse:List of 4
##   ..$ title : chr "Web scraping"
##   ..$ pageid: int 5544299
##   ..$ revid : int 143659932
##   ..$ text  :List of 1
##   .. ..$ *: chr "&lt;div class=\"mw-parser-output\"&gt;&lt;p&gt;&lt;i&gt;&lt;b&gt;Web scraping&lt;/b&gt;&lt;/i&gt; o raspado web, es una t√©cnica utilizada mediante "| __truncated__
##  - attr(*, "class")= chr "pcontent"
```
]


---

## Wikipedia: usando WikipediR 4

Texto sobre Web scraping.

.font40[

```r
cont_wiki$parse$text$`*` |&gt; # Texto del requerimiento
  read_html() |&gt; html_text() |&gt; 
  cat()
```

```
## Web scraping o raspado web, es una t√©cnica utilizada mediante programas de software para extraer informaci√≥n de sitios web.[1]‚Äã Usualmente, estos programas simulan la navegaci√≥n de un humano en la World Wide Web ya sea utilizando el protocolo HTTP manualmente, o incrustando un navegador en una aplicaci√≥n.
## El web scraping est√° muy relacionado con la indexaci√≥n de la web, la cual indexa la informaci√≥n de la web utilizando un robot y es una t√©cnica universal adoptada por la mayor√≠a de los motores de b√∫squeda. Sin embargo, el web scraping se enfoca m√°s en la transformaci√≥n de datos sin estructura en la web (como el formato HTML) en datos estructurados que pueden ser almacenados y analizados en una base de datos central, en una hoja de c√°lculo o en alguna otra fuente de almacenamiento. Alguno de los usos del web scraping son la comparaci√≥n de precios en tiendas, la monitorizaci√≥n de datos relacionados con el clima de cierta regi√≥n, la detecci√≥n de cambios en sitios webs y la integraci√≥n de datos en sitios webs. Tambi√©n es utilizado para obtener informaci√≥n relevante de un sitio a trav√©s de los rich snippets. 
## En los √∫ltimos a√±os el web scraping se ha convertido en una t√©cnica muy utilizada dentro del sector del posicionamiento web gracias a su capacidad de generar grandes cantidades de datos para crear contenidos de calidad.[2]‚Äã
## 
## √çndice
## 1 T√©cnicas
## 2 Cuestiones legales
## 3 Medidas para detener a los scrapers
## 4 Beneficios
## 5 Herramientas notables
## 6 V√©ase tambi√©n
## 7 Referencias
## 
## 
## T√©cnicas[editar]
## Web scraping es el proceso de recopilar informaci√≥n de forma autom√°tica de la Web. Es un campo con desarrollos activos, compartiendo un prop√≥sito en com√∫n con la visi√≥n de la Web sem√°ntica. Utiliza soluciones pr√°cticas basadas en tecnolog√≠as existentes que son com√∫nmente ad hoc. Existen distintos niveles de automatizaci√≥n que las existentes tecnolog√≠as de Web Scraping pueden brindar:
## 
## ¬´Copiar y pegar¬ª humano: algunas veces incluso las mejores t√©cnicas de web scraping no pueden reemplazar el examen manual de un humano, y a veces esta puede ser la √∫nica v√≠a de soluci√≥n cuando el sitio que tenemos en mente pone ciertas barreras para prevenir que se creen softwares para realizar tareas autom√°ticas en este.
## Uso de expresiones regulares: una posible v√≠a para extraer informaci√≥n de p√°ginas webs pueden ser las expresiones regulares, aunque com√∫nmente no se recomienda utilizarlas para parsear el formato HTML.
## Protocolo HTTP: p√°ginas webs est√°ticas y din√°micas pueden ser obtenidas haciendo peticiones HTTP al servidor remoto utilizando sockets, etc.
## Algoritmos de miner√≠a de datos: muchos sitios webs tienen grandes colecciones de p√°ginas generadas din√°micamente a partir de una base de datos. Datos de la misma categor√≠a aparecen usualmente en p√°ginas similares mediante un script o una plantilla. En la miner√≠a de datos, un programa detecta estas plantillas en un contexto espec√≠fico y extrae su contenido.
## Parsers de HTML: Algunos lenguajes, como XQuery y HTQL pueden ser utilizados para parsear documentos, recuperar y transformar el contenido de documentos HTML.
## Aplicaciones para web scraping: existen muchas aplicaciones disponibles que pueden ser utilizadas para personalizar soluciones de Web Scraping. Estas aplicaciones podr√≠an reconocer autom√°ticamente la estructura de cierta p√°gina o brindar una interfaz al usuario donde este pudiera seleccionar los campos que son de inter√©s dentro del documento. De esta forma no es necesario escribir manualmente c√≥digo para realizar estas tareas.
## Reconocimiento de informaci√≥n sem√°ntica: las p√°ginas que son analizadas podr√≠an incluir metadatos o cierta informaci√≥n sem√°ntica como anotaciones o comentarios, los cuales pueden ser usados com√∫nmente. Si estas anotaciones est√°n en las mismas p√°ginas, como sucede con los microformatos, estas podr√≠an ser de utilidad cuando parseamos el DOM del documento. En otro caso, las anotaciones, organizadas en una capa sem√°ntica, son almacenadas y manejadas de forma separada desde otras p√°ginas, por lo que los scrapers pueden recuperar estos esquemas y las instrucciones desde esta capa antes de analizar los documentos.[3]‚ÄãCuestiones legales[editar]
## El web scraping pudiera ir en contra de los t√©rminos de uso de algunos sitios webs. El cumplimiento de estos t√©rminos no est√° totalmente claro.[4]‚Äã Mientras que la duplicaci√≥n de expresiones originales puede ser en muchos casos ilegal, en Estados Unidos la corte dict√≥ en el caso Feist Publications v. Rural Telephone Service que la duplicaci√≥n de hechos es permitida. Las cortes de Estados Unidos en ciertas ocasiones han reconocido que ciertos usos de los scrapers no deber√≠an estar permitidos. Podr√≠a considerarse una computadora como una propiedad personal, y de esta forma el scraper estar√≠a entrando sin autorizaci√≥n en esta propiedad. En el caso m√°s conocido, eBay vs Bidder's Edge, la segunda empresa tuvo que parar de realizar peticiones autom√°ticas al sitio de eBay. En este caso, Bidder's Edge pujaba autom√°ticamente por ciertos productos en este sitio.
## Uno de las principales pruebas de scraping involucr√≥ a American Airlines y a una empresa llamada FareChase. American Airlines gan√≥ esta batalla, haciendo que FareChase parara de vender un software que le permit√≠a a los usuarios comparar tarifas en l√≠nea si el sitio de American Airlines era incluido. La aerol√≠nea dijo que las b√∫squedas de FareChase entraban sin autorizaci√≥n en los servidores cuando recopilaban la informaci√≥n p√∫blicamente disponible.
## Aunque las decisiones actualmente tomadas no son uniformes, es dif√≠cil ignorar que un patr√≥n est√° emergiendo, en el cual podemos ver que las cortes est√°n prepar√°ndose para proteger el contenido propietario en sitios webs comerciales, previendo de esta forma que este sea utilizado sin el consentimiento de los propietarios de los sitios. Sin embargo, el grado de protecci√≥n de estos contenidos a√∫n no est√° establecido, y depender√° del tipo de acceso realizado por los scrapers, de la cantidad de informaci√≥n recopilada y del grado en el que afecten estos factores al propietario del sitio web.
## 
## Medidas para detener a los scrapers[editar]
## El administrador de un sitio web puede utilizar varias t√©cnicas para detener o disminuir los pedidos de los scrapers. Algunas t√©cnicas incluyen:
## 
## A√±adir entradas al fichero robots.txt. Algunos bots pueden ser detenidos de esta forma. Hay personas que piensan que el bot de Google puede ser detenido as√≠, cosa que el propio buscador ha negado.
## Bloquear la direcci√≥n IP. Esto tambi√©n bloquear√° todos los accesos desde esa misma IP, por lo que los usuarios no podr√°n navegar por el sitio web si acceden desde esta.
## Deshabilitar cualquier interfaz de programaci√≥n de aplicaciones que el sitio web pudiera estar brindando.
## Los bots o scrapers algunas veces declaran quienes son, y gracias a esto pueden ser bloqueados. ¬´Googlebot¬ª es un ejemplo. Algunos scrapers no hacen lo que el bot de G., para que no se pueda distinguir entre un navegador com√∫n y ellos.
## Monitorear el exceso de tr√°fico proveniente de cierta IP.
## A√±adir un captcha u otro sistema de verificaci√≥n manual al sitio web. No se garantiza el completo bloqueo de los scrapers, pero mediante esta t√©cnica se dificulta el acceso de los mismos a los sitios webs.
## Servicios comerciales antibots: algunas empresas ofrecen servicios antibots y antiscraping.[5]‚Äã
## Incrementar el uso de JavaScript y AJAX. De esta forma es m√°s dif√≠cil para los scrapers simular las peticiones como si fueran un navegador com√∫n, aunque har√° que usuarios leg√≠timos dejen de poder ver la p√°gina.La mayor√≠a de estos m√©todos suponen una merma importante en la usabilidad del sitio web en cuesti√≥n y los beneficios pueden ser muy puntuales.
## 
## Beneficios[editar]
## Pese al planteamiento negativo de ciertos sectores, el rastreo autom√°tico y scraping son muy importantes para mantener la historia de Internet. Las iniciativas de archivado web se basan mayoritariamente en esta t√©cnica.
## 
## Herramientas notables[editar]
## 
## UIPath
## Apache Camel
## Automation Anywhere
## Convertigo
## cURL
## Data Toolbar
## Firebug
## Greasemonkey
## HtmlUnit
## Node.js
## HTTrack
## iMacros
## Aptana Jaxer
## nokogiri
## watir
## Wget
## WSO2 Mashup Server
## HtmlAgilityPack
## BeautifulSoup
## Scrapy
## V√©ase tambi√©n[editar]
## Miner√≠a de datos
## Mashup (aplicaci√≥n web h√≠brida)
## Spamdexing
## Corpus ling√º√≠stico
## Ara√±a web
## Metadato
## Screen scraping.Referencias[editar]
## ‚Üë  Mart√≠, Marq (8 de abril de 2016). ¬´¬øQu√© es el Web scraping? Introducci√≥n y herramientas¬ª (html). Sitelab Espa√±a. Archivado desde el original el 29 de julio de 2017. Consultado el 30 de marzo de 2020. ¬´El web scraping es una t√©cnica que sirve para extraer informaci√≥n de p√°ginas web de forma automatizada. Si traducimos del ingl√©s su significado vendr√≠a a significar algo as√≠ como ‚Äúescarbar una web‚Äù.¬ª¬† 
## 
## ‚Üë  Mart√≠, Marq (8 de abril de 2016). ¬´¬øQu√© es el Web scraping? Introducci√≥n y herramientas¬ª (html). Sitelab Espa√±a. Archivado desde el original el 29 de julio de 2017. Consultado el 30 de marzo de 2020. ¬´Para controlar la imagen y la visibilidad de nuestra marca en internet: a trav√©s de un scrapeo podemos automatizar la posici√≥n por la que varios art√≠culos de nuestra web se posicionan en Google o, por ejemplo, controlar la presencia del nombre de nuestra marca en determinados foros. Ejemplo: rastrear la posici√≥n en Google de todas las entradas de nuestro blog.¬ª¬† 
## 
## ‚Üë http://www.gooseeker.com/en/node/knowledgebase/freeformat
## 
## ‚Üë https://web.archive.org/web/20020308222536/http://www.chillingeffects.org/linking/faq.cgi#QID596
## 
## ‚Üë https://s3.us-west-2.amazonaws.com/research-papers-mynk/Breaking-Fraud-And-Bot-Detection-Solutions.pdf
## 
## 
## .mw-parser-output .mw-authority-control{margin-top:1.5em}.mw-parser-output .mw-authority-control .navbox hr:last-child{display:none}.mw-parser-output .mw-authority-control .navbox+.mw-mf-linked-projects{display:none}.mw-parser-output .mw-authority-control .mw-mf-linked-projects{display:flex;padding:0.5em;border:1px solid #c8ccd1;background-color:#eaecf0;color:#222222}.mw-parser-output .mw-authority-control .mw-mf-linked-projects ul li{margin-bottom:0}Control de autoridades
## Proyectos Wikimedia
##  Datos: Q665452
##  Datos: Q665452
```
]


---

## Spotify

.pull-left[
Uno de los mayores proveedores de servicio de m√∫sica del mundo. 
Tiene disponible una API para la integraci√≥n de su servicio con otras aplicaciones. Podemos usarla para obtener informaci√≥n

- Spotify API: [quick start](https://developer.spotify.com/documentation/web-api/quick-start/)

- Requiere tener cuenta en Spotify y [crear un token](https://developer.spotify.com/dashboard/).
]

.pull-right[
![Spotify dashboard](./class_9_files/spotify_dashboard.jpeg)
]


---

## Spotify: API 1

Revisemos la [API de Spotify](https://developer.spotify.com/documentation/web-api/). Acciones de inter√©s.

- [`Search`](https://developer.spotify.com/documentation/web-api/reference/#/operations/search): Buscar.
  
- [`get-playlist`](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-playlist): Datos sobre una lista.
  
- [`get-several-audio-features`](https://developer.spotify.com/documentation/web-api/reference/#/operations/get-several-audio-features): Informaci√≥n psico--ac√∫stica de canciones.



---

## Spotify: API 2

B√∫squeda de g√©nero metal usando la API directamente. Ped√≠ el token de acceso usando `spotifyr`.

.font70[

```r
s_met &lt;- GET('https://api.spotify.com/v1/search',
             query = list(q = 'genre:metal', 
                          market = 'CL', 
                          type = 'artist', 
                          limit = 8),
             accept_json(),
             add_headers(Authorization = str_glue("Bearer {spotifyr::get_spotify_access_token()}")))

df_met &lt;- s_met |&gt; content('text') |&gt; 
  jsonlite::fromJSON()

df_met$artists$items |&gt; 
  as_tibble() |&gt; unpack(followers, names_repair = 'minimal') |&gt;
  select(id, name, popularity, total)
```

```
## # A tibble: 8 √ó 4
##   id                     name                  popularity    total
##   &lt;chr&gt;                  &lt;chr&gt;                      &lt;int&gt;    &lt;int&gt;
## 1 2ye2Wgw4gimLv2eAKyk1NB Metallica                     79 21532309
## 2 5eAWCfyUhZtHHtBdNk56l1 System Of A Down              76  8292787
## 3 3qm84nBOXUEQ2vnTfUTTFC Guns N' Roses                 77 24791068
## 4 0L8ExT028jH3ddEcZwqJJ5 Red Hot Chili Peppers         81 18236810
## 5 6XyY86QOPPrYVGvF9ch6wz Linkin Park                   81 21977271
## 6 05fG473iIaoy82BF1aGhL8 Slipknot                      76  8524614
## 7 58lV9VcRSjABbAbfWS6skp Bon Jovi                      76 10858164
## 8 6wWVKhxIU2cEi0K81v7HvP Rammstein                     79  7287759
```
]


---

## Spotify: spotifyr 1

Envuelve los llamados a la API de Spotify en funciones de R.
Puede verse su [referencia](https://www.rcharlie.com/spotifyr/reference/index.html)

B√∫squeda an√°loga a la anterior:

.font70[

```r
library(spotifyr)

df_met &lt;- get_genre_artists('metal', limit = 8)
df_met |&gt; 
  select(id, name, popularity, followers.total)
```

```
## # A tibble: 8 √ó 4
##   id                     name                    popularity followers.total
##   &lt;chr&gt;                  &lt;chr&gt;                        &lt;int&gt;           &lt;int&gt;
## 1 6XyY86QOPPrYVGvF9ch6wz Linkin Park                     81        21977271
## 2 2ye2Wgw4gimLv2eAKyk1NB Metallica                       79        21532309
## 3 0L8ExT028jH3ddEcZwqJJ5 Red Hot Chili Peppers           81        18236810
## 4 05fG473iIaoy82BF1aGhL8 Slipknot                        76         8524614
## 5 5t28BP42x2axFnqOOMg3CM Five Finger Death Punch         73         5531932
## 6 6Ghvu1VvMGScGpOUJBAHNH Deftones                        72         2675946
## 7 2xiIXseIJcq3nG7C8fHeBj Three Days Grace                73         5252431
## 8 5eAWCfyUhZtHHtBdNk56l1 System Of A Down                76         8292787
```
]


---

## Spotify: spotifyr 2 

Cambiamos los criterios de b√∫squeda para encontrar podcasts.

.font70[

```r
df_pod &lt;- search_spotify(q = 'podcast', type = 'show', market = 'CL', limit = 10)
df_pod |&gt; 
  select(id, name, total_episodes, description)
```

```
## # A tibble: 10 √ó 4
##    id                     name                        total_episodes description
##    &lt;chr&gt;                  &lt;chr&gt;                                &lt;int&gt; &lt;chr&gt;      
##  1 2nAf8IDQG1sPEwAKdG2DyM Despertando Podcast                    556 ¬øQu√© pasar‚Ä¶
##  2 0sGGLIDnnijRPLef7InllD Entiende Tu Mente                      238 Seguro que‚Ä¶
##  3 1NVpfucRZLNVQmPp1MNlxc Vivi Pedraglio | Podcast               129 Vivi is an‚Ä¶
##  4 6S7DckQZ7RzFVbvUF8rY1k Presentaciones Felipe Avel‚Ä¶             20 Distintas ‚Ä¶
##  5 1w9Me4TrRiDOuK3OsJ2VAW Durmiendo Podcast                      298 ¬°Desp√≠dete‚Ä¶
##  6 3X1Gb5GOl3Xv3VilVRhB0t Weona Que Creici                       144 Que los ho‚Ä¶
##  7 6f9fN5uEZOjAbl7csWyb0P Emisor Podcasting. - Esto ‚Ä¶            100 Marco y Ma‚Ä¶
##  8 17dk0hYDmVq7EzGXC8y4u6 Filosof√≠a, Psicolog√≠a, His‚Ä¶            191 Relatos br‚Ä¶
##  9 1sOuGn3YfjXW2eBmVEuyRW ELO PODCAST                            341 Me gusta c‚Ä¶
## 10 4mWFWpLVAjn7YyLoo0uqTe Weona Full S√≠                           66 Coni y Nac‚Ä¶
```
]

---

## Spotify: spotifyr listas

Exploremos las caractar√≠sticas de canciones gracias a la lista 
[top 50 canciones en Chile](https://open.spotify.com/playlist/37i9dQZEVXbL0GavIqMTeb). 

.font70[

```r
df_top &lt;- get_playlist('37i9dQZEVXbL0GavIqMTeb') # ID de la lista.
df_top_track &lt;- df_top$tracks$items |&gt; as_tibble() |&gt; distinct()

suppressMessages(
  # Seleccionar y limpiar solo alguna de las variables disponibles
  df_top_track_sel &lt;- df_top_track |&gt; 
    mutate(track.id, track.name, track.popularity, track.album.release_date, 
           name = map(track.album.artists, 'name'),
           .keep = 'none') |&gt; 
    unnest_wider(name, names_repair = 'unique')
)

df_top_track_sel |&gt; head()
```

```
## # A tibble: 6 √ó 7
##   track.id        track.name track.popularity track.album.rel‚Ä¶ ...5  ...6  ...7 
##   &lt;chr&gt;           &lt;chr&gt;                 &lt;int&gt; &lt;chr&gt;            &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;
## 1 6wtZPYBIXUvCpX‚Ä¶ ULTRA SOL‚Ä¶               79 2022-06-16       Poli‚Ä¶ Pail‚Ä¶ Feid 
## 2 6Sq7ltF9Qa7SNF‚Ä¶ Me Porto ‚Ä¶               99 2022-05-06       Bad ‚Ä¶ &lt;NA&gt;  &lt;NA&gt; 
## 3 5Eax0qFko2dh7R‚Ä¶ Efecto                   95 2022-05-06       Bad ‚Ä¶ &lt;NA&gt;  &lt;NA&gt; 
## 4 3k3NWokhRRkEPh‚Ä¶ Ojitos Li‚Ä¶               98 2022-05-06       Bad ‚Ä¶ &lt;NA&gt;  &lt;NA&gt; 
## 5 6Xom58OOXk2SoU‚Ä¶ Moscow Mu‚Ä¶               97 2022-05-06       Bad ‚Ä¶ &lt;NA&gt;  &lt;NA&gt; 
## 6 40w8JmvwYUP2HU‚Ä¶ Me Arrepe‚Ä¶               81 2022-03-30       Ak4:‚Ä¶ Pail‚Ä¶ Cris‚Ä¶
```
]


---

## Spotify: spotifyr canciones 1

Con el `id` de las canciones, podemos obtener caracter√≠sticas musicales de las canciones.

.font70[

```r
df_track_af &lt;- get_track_audio_features(df_top_track_sel$track.id)

head(df_track_af)
```

```
## # A tibble: 6 √ó 18
##   danceability energy   key loudness  mode speechiness acousticness
##          &lt;dbl&gt;  &lt;dbl&gt; &lt;int&gt;    &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt;        &lt;dbl&gt;
## 1        0.909  0.824     1    -4.63     1      0.0797       0.0777
## 2        0.911  0.712     1    -5.11     0      0.0817       0.0901
## 3        0.801  0.475     7    -8.80     0      0.0516       0.141 
## 4        0.647  0.686     3    -5.74     0      0.0413       0.08  
## 5        0.804  0.674     5    -5.45     0      0.0333       0.294 
## 6        0.861  0.786     0    -4.93     1      0.164        0.289 
## # ‚Ä¶ with 11 more variables: instrumentalness &lt;dbl&gt;, liveness &lt;dbl&gt;,
## #   valence &lt;dbl&gt;, tempo &lt;dbl&gt;, type &lt;chr&gt;, id &lt;chr&gt;, uri &lt;chr&gt;,
## #   track_href &lt;chr&gt;, analysis_url &lt;chr&gt;, duration_ms &lt;int&gt;,
## #   time_signature &lt;int&gt;
```
]


---

## Spotify: spotifyr canciones 2

Gr√°fico con la posici√≥n relativa de las canciones seg√∫n 5 caracter√≠sticas.

.pull-left.font70[

```r
df_top_track_sel &lt;- bind_cols(df_top_track_sel, df_track_af)

gg &lt;- df_top_track_sel |&gt; 
  mutate(pos = row_number()) |&gt;
  pivot_longer(cols = c(danceability, energy, speechiness, acousticness, liveness, liveness),
               names_to = 'variable', values_to = 'valor') |&gt; 
  ggplot(aes(x = variable, y = valor, colour = track.popularity)) +
  geom_point(aes(size = rev(pos)),
             alpha = 0.5,
             show.legend = FALSE) + theme_minimal() +
  labs(title = 'Caracter√≠sticas de las 100 canciones en Chile',
       subtitle = 'Lista Top 50 ‚Äî Chile, Spotify', x = NULL)
```
]

.pull-right.font70[

```r
gg
```

&lt;img src="class_9_files/figure-html/unnamed-chunk-18-1.png" style="display: block; margin: auto;" /&gt;
]

---

## Twitter: API

La APIv2 de Twitter se puede consultar [ac√°](https://developer.twitter.com/en/docs/twitter-api). 

- Existen distintos [niveles de acceso][tw_niveles] a la API.

  - *Essencial* y *Elevated* no permiten el acceso a [search][tw_s] y [count][tw_c]. Pueden acceder al [stream][tw_st].
  
  - Se puede pedir acceso a Twitter Acad√©mico.

  - Packetes: [`rtweet`](https://docs.ropensci.org/rtweet) [`RTwitterV2`](https://github.com/MaelKubli/RTwitterV2) [`academictwitteR`](https://github.com/cjbarrie/academictwitteR)

[tw_niveles]: https://developer.twitter.com/en/docs/twitter-api/getting-started/about-twitter-api#item0
[tw_s]: https://developer.twitter.com/en/docs/twitter-api/tweets/search/introduction
[tw_c]: https://developer.twitter.com/en/docs/twitter-api/tweets/counts/introduction
[tw_st]: https://developer.twitter.com/en/docs/twitter-api/tweets/filtered-stream/introduction

---

## Twitter: rtweet 1

Instalar versi√≥n en desarrollo:

```r
install.packages("rtweet", repos = 'https://ropensci.r-universe.dev')
```


```r
suppressPackageStartupMessages(library(rtweet))

rtweet::auth_setup_default() # pedir credenciales
```

```
## Using default authentication available.
## Reading auth from '/Users/caayala/Library/Preferences/org.R-project.R/R/rtweet/default.rds'
```


```r
rtweet::auth_get() # ver credenciales
```

```
## &lt;Token&gt;
## &lt;oauth_endpoint&gt;
##  request:   https://api.twitter.com/oauth/request_token
##  authorize: https://api.twitter.com/oauth/authenticate
##  access:    https://api.twitter.com/oauth/access_token
## &lt;oauth_app&gt; rtweet
##   key:    6j7Ig4xzHlBr8uUJ5A4Ym0NTf
##   secret: &lt;hidden&gt;
## &lt;credentials&gt; oauth_token, oauth_token_secret, user_id, screen_name
## ---
```


---

## Twitter: rtweet 2

Tweets del usuario @rstudio.

.font70[

```r
tweets &lt;- rtweet::get_timeline('rstudio')
dim(tweets)
```

```
## [1] 100  43
```


```r
tweets |&gt; 
  select(id, created_at, text) |&gt; head()
```

```
## # A tibble: 6 √ó 3
##        id created_at          text                                              
##     &lt;dbl&gt; &lt;dttm&gt;              &lt;chr&gt;                                             
## 1 1.54e18 2022-06-22 14:31:51 "Want to learn how to produce elegant and inspiri‚Ä¶
## 2 1.54e18 2022-06-22 12:23:04 "In their final installment of Programming Games ‚Ä¶
## 3 1.54e18 2022-06-21 12:03:39 "Join us now on YouTube live for our Enterprise M‚Ä¶
## 4 1.54e18 2022-06-21 11:10:00 "RT @quarto_pub: Want to get started with or get ‚Ä¶
## 5 1.54e18 2022-06-17 15:25:49 "On R Views - Introducing @f2harrell‚Äôs new book, ‚Ä¶
## 6 1.54e18 2022-06-17 12:28:40 "RT @rstudio_glimpse: TinyTeX users, you can inst‚Ä¶
```
]


---

## Twitter: academictwitteR



Revisar el usuario [@rstudio](https://twitter.com/rstudio).


```r
suppressPackageStartupMessages(library(academictwitteR))
tuser_id &lt;- get_user_id('rstudio')
```

.font70[

```r
get_user_profile(tuser_id)
```

```
## Processing from 1 to 1
```

```
##   username        id protected               created_at location
## 1  rstudio 235261861     FALSE 2011-01-07T19:13:28.000Z   Boston
##                                                              profile_image_url
## 1 https://pbs.twimg.com/profile_images/1273974016265486349/qghv719Z_normal.jpg
##                      url public_metrics.followers_count
## 1 http://t.co/sNW3mienR9                         131863
##   public_metrics.following_count public_metrics.tweet_count
## 1                            662                       2963
##   public_metrics.listed_count verified
## 1                        2234    FALSE
##                                                                 urls    name
## 1 0, 22, http://t.co/sNW3mienR9, http://www.rstudio.com, rstudio.com RStudio
##                                                                                         description
## 1 Open source and enterprise-ready professional software for data science teams using R and Python.
```
]


---

## Twitter: academictwitteR tweets Encuesta CEP 1

Tweets de la cuanta @rstudio, an√°logo al uso de `rtweet`.

.font70[

```r
tweets_user &lt;- academictwitteR::get_user_timeline(
  x = tuser_id,
  start_tweets = f_date_for_twitter(as.Date('2022-06-17')),
  end_tweets = f_date_for_twitter(as.Date('2022-06-23')),
  bearer_token = Sys.getenv('TWITTER_BEARER_CAA')) |&gt; 
  as_tibble()
```

```
## user:  235261861 
## Total pages queried: 1 (tweets captured this page: 6).
## This is the last page for : finishing collection.
```

```r
tweets_user |&gt; 
  select(id, created_at, text)
```

```
## # A tibble: 6 √ó 3
##   id                  created_at               text                             
##   &lt;chr&gt;               &lt;chr&gt;                    &lt;chr&gt;                            
## 1 1539677562951057408 2022-06-22T18:31:51.000Z "Want to learn how to produce el‚Ä¶
## 2 1539645152238501888 2022-06-22T16:23:04.000Z "In their final installment of P‚Ä¶
## 3 1539277877929054208 2022-06-21T16:03:39.000Z "Join us now on YouTube live for‚Ä¶
## 4 1539264378154848256 2022-06-21T15:10:00.000Z "RT @quarto_pub: Want to get sta‚Ä¶
## 5 1537879205035143168 2022-06-17T19:25:49.000Z "On R Views - Introducing @f2har‚Ä¶
## 6 1537834624335851520 2022-06-17T16:28:40.000Z "RT @rstudio_glimpse: TinyTeX us‚Ä¶
```
]

---

## Twitter: academictwitteR tweets Encuesta CEP 2

Buscar tweets de un tema espec√≠fico.
Solo para cuentas acad√©micas.

.font70[


```r
try(
  get_all_tweets(
    query = '"Encuesta CEP"',
    start_tweets = f_date_for_twitter(as.Date('2022-06-17')),
    end_tweets = f_date_for_twitter(as.Date('2022-06-23')),
    bearer_token = Sys.getenv('TWITTER_BEARER_CAA')) # Error con este token.
)
```

```
## query:  "Encuesta CEP" 
## Error in make_query(url = endpoint_url, params = params, bearer_token = bearer_token,  : 
##   something went wrong. Status code: 403
```
]


---

## Twitter: academictwitteR tweets Encuesta CEP 3

Con una cuenta acad√©mica se puede buscar en un tema espec√≠fico.

.font70[

```r
tweets_tema &lt;- get_all_tweets(
  query = '"Encuesta CEP"',
  start_tweets = f_date_for_twitter(as.Date('2022-06-17')),
  end_tweets = f_date_for_twitter(as.Date('2022-06-23')),
  bearer_token = Sys.getenv('TWITTER_BEARER')) |&gt; as_tibble()
```

```
## Warning: Recommended to specify a data path in order to mitigate data loss when
## ingesting large amounts of data.
```

```
## Warning: Tweets will not be stored as JSONs or as a .rds file and will only be
## available in local memory if assigned to an object.
```

```
## query:  "Encuesta CEP" 
## Total pages queried: 1 (tweets captured this page: 100).
## Total tweets captured now reach 100 : finishing collection.
```


```r
tweets_tema |&gt; 
  select(id, created_at, text) |&gt; 
  head()
```

```
## # A tibble: 6 √ó 3
##   id                  created_at               text                             
##   &lt;chr&gt;               &lt;chr&gt;                    &lt;chr&gt;                            
## 1 1539613492491128832 2022-06-22T14:17:15.000Z "La Cadem es la encuesta menos f‚Ä¶
## 2 1539461559839506434 2022-06-22T04:13:32.000Z "RT @MauricioRojasmr: Seg√∫n la e‚Ä¶
## 3 1539416893391458305 2022-06-22T01:16:03.000Z "@kamiluru @DraMLCordero Compren‚Ä¶
## 4 1539390533893623809 2022-06-21T23:31:18.000Z "https://t.co/CcpybKAvKW y se qu‚Ä¶
## 5 1539384392442777600 2022-06-21T23:06:54.000Z "@DraMLCordero @MielExtrema Pued‚Ä¶
## 6 1539325998419693575 2022-06-21T19:14:51.000Z "RT @MauricioRojasmr: Seg√∫n la e‚Ä¶
```
]


---

## Twitter: academictwitteR tweets Encuesta CEP 4

Con una cuenta acad√©mica se puede buscar en un tema espec√≠fico.

.font70[

```r
tweetsr_tema &lt;- rtweet::stream_tweets(query = '"Encuesta CEP"')
```

```
## Writing to '/var/folders/hr/tjq1vv1s0_l0vn12krk6kq8h0000gn/T//RtmpM31D8P/
## stream_tweets167e92a2e5a6c.json'
```

```r
tweetsr_tema |&gt; 
  select(id, created_at, text) |&gt; 
  head()
```

```
##             id          created_at
## 1 1.540079e+18 2022-06-23 17:07:02
## 2 1.540079e+18 2022-06-23 17:07:02
## 3 1.540079e+18 2022-06-23 17:07:02
## 4 1.540079e+18 2022-06-23 17:07:02
## 5 1.540079e+18 2022-06-23 17:07:02
## 6 1.540079e+18 2022-06-23 17:07:02
##                                                                                                                                           text
## 1                                                                                                                 se me pas√≥ volando la semana
## 2 RT @KarinaFeets: If you‚Äôre not willing to make financial sacrifices in order to be beneath my perfect feet, then you are not worthy. Just l‚Ä¶
## 3             RT @Jolly_Jack: Everyone else forgets you, but I never will. Happy Birthday, Doctor. Have a new costume. https://t.co/it3f4yozTm
## 4                                                                      RT @MULHERFD8: Algu√©m pra chupar minha buceta?? https://t.co/Xmj44fDbTF
## 5                          @TasosGionis1 @AntVas7 @7Vercost ŒΩŒ± œÄŒ±œÅŒµœÑŒµ œÑŒøŒΩ ŒµŒºœÄŒ±œÄŒµ...ŒøŒªŒøŒπ ŒøŒπ ŒºŒ±ŒªŒ±Œ∫ŒµœÇ ŒµŒªŒªŒ∑ŒΩŒµœÇ ŒµŒπŒΩŒ±Œπ Œ∫Œ±Œπ œÉŒ∫Œ±ŒøœÖœÑŒµœÅ Œ∫Œ±Œπ ŒºŒ±ŒΩŒ±ŒΩœÑŒ∂ŒµœÅ...
## 6                                                            RT @hruthik284: bir #bornova hayatƒ±m M√ºkemmel  #kar≈üƒ±yaka https://t.co/6wsCNONqLU
```
]

---

## Twitter: RTwitterV2 timeline 1

Con una cuenta acad√©mica se puede buscar en un tema espec√≠fico.

.font70[

```r
library(RTwitterV2)

tweets_tema &lt;- get_timelines_v2(user_id = tuser_id, n = 100, 
                                token = Sys.getenv('TWITTER_BEARER_CAA')) |&gt; 
  as_tibble()

tweets_tema |&gt; 
  select(conversation_id, created_at, text) |&gt; 
  head()
```

```
## # A tibble: 6 √ó 3
##   conversation_id     created_at               text                             
##   &lt;chr&gt;               &lt;chr&gt;                    &lt;chr&gt;                            
## 1 1534947704786128904 2022-06-09T17:17:05.000Z "Announcing vetiver! üè∫\n\nvetiv‚Ä¶
## 2 1527004401986064385 2022-05-18T19:13:14.000Z "Check out Part 3 of R Markdown ‚Ä¶
## 3 1509966787391021058 2022-04-01T18:51:50.000Z "tidymodels digest, Q1 2022.\nti‚Ä¶
## 4 1518634132158369792 2022-04-25T16:52:46.000Z "Tables with #rstats! ‚ÄìYou know ‚Ä¶
## 5 1508476743362887680 2022-03-28T16:10:56.000Z "Creating a custom word list for‚Ä¶
## 6 1504945299420180481 2022-03-18T22:18:14.000Z "And if you‚Äôre looking for tips ‚Ä¶
```
]

---

## Twitter: RTwitterV2 timeline 2

Con una cuenta acad√©mica se puede buscar en un tema espec√≠fico.

.font70[

```r
tweets_tema &lt;- recent_search(search_query = "Encuesta CEP",
                             start_time = f_date_for_twitter(as.Date('2022-06-17')),
                             end_time = f_date_for_twitter(as.Date('2022-06-23')),
                             n = 100,
                             token = Sys.getenv('TWITTER_BEARER_CAA')) |&gt; 
  as_tibble()

tweets_tema |&gt; 
  select(conversation_id, created_at, text) |&gt; 
  head()
```

```
## # A tibble: 6 √ó 3
##   conversation_id     created_at               text                             
##   &lt;chr&gt;               &lt;chr&gt;                    &lt;chr&gt;                            
## 1 1538866916395102208 2022-06-20T12:50:38.000Z "No debe estar ninguna figura po‚Ä¶
## 2 1537776838612615168 2022-06-17T12:39:03.000Z "@JanisMeneses_D6 o eres mentiro‚Ä¶
## 3 1539613492491128832 2022-06-22T14:17:15.000Z "La Cadem es la encuesta menos f‚Ä¶
## 4 1539052270557442048 2022-06-21T01:07:10.000Z "Hay algo sospechoso en est√°s en‚Ä¶
## 5 1539231969820561408 2022-06-21T13:01:13.000Z "RT @latercera: Encuesta CEP: go‚Ä¶
## 6 1537597668163080192 2022-06-17T00:47:05.000Z "RT @MauricioRojasmr: Seg√∫n la e‚Ä¶
```
]



---

## En la pr√≥xima clase‚Ä¶ 

- Preguntas sobre trabajo final.

- √âtica del web scraping.


---
class: inverse, middle

Presentaci√≥n y c√≥digo en GitHub:  
&lt;https://github.com/caayala/web_scraping_soc40XX&gt;  

&lt;https://caayala.github.io/web_scraping_soc40XX/&gt;


---
class: inverse, center, middle

.huge[
¬°Gracias!
]

&lt;br&gt;
Cristi√°n Ayala  
&lt;https://blog.desuc.cl/&gt;  
&lt;http://github.com/caayala&gt;



    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"ratio": "16:9",
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"slideNumberFormat": "%current%"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
