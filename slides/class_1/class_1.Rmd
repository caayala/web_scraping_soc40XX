---
title: "Introducción"
subtitle: "Web Scrapping y acceso a datos desde la web con R"
author: "<br>Cristián Ayala<br> Director DESUC"
date: "[github.com/caayala](https://github.com/caayala)"
output:
  xaringan::moon_reader:
    lib_dir: "libs"
    css: ["default", "default-fonts", "../gentle-r.css"]
    df_print: default
    nature:
      ratio: 16:9
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: true
      slideNumberFormat: "%current%"
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo = FALSE
suppressPackageStartupMessages(library(tidyverse))
library(knitr)
opts_chunk$set(cache.path = "class_1_files/class_1_cache/html/")
```


## Expectativas y nivelación

- ¿Cuál fue su motivación para tomar este curso?

- ¿Que tanto saben de la *web*?

- Recordar algunas nociones de R que nos ayudarán en lo que sigue del curso.


---

## Recomendaciones iniciales

- Instalar *[R 4.2](https://cloud.r-project.org/)*: Uso la nueva *pipe base* en mis ejemplos (`|>`)
    - **Cuidado**, será necesario re--instalar todos los paquetes. 
    
- Instalar la última versión de *[RStudio](https://www.rstudio.com/products/rstudio/download/#download)*.
    - Soporte para `|>` y mejoras varias.
    
- Acceder a repositorio de Github para acceder a material de clases y ejercicios.
    - [Repositorio del curso](https://github.com/caayala/web_scraping_soc40XX)


---

## ¿Por qué web scraping?

Definición:

> Capturar datos estructurados de una forma automátizada

Si ya han *copiado--&--pegado* información de la web a un archivo, guardado imágenes o sonidos manualmente, ya hicieron web scraping. 

Ahora queremos tener la capacidad para **automatizar** ese proceso.

<br />

Ej: Comparar precios en un sitio como [Knasta](https://knasta.cl).


---

## ¿Por qué web scraping?

¡Tanta información disponible!

.pull-left[
- Permite **automatizar** la toma de gran cantidad de datos.

- Capacidad de **complementar** e **integrar** distintas fuentes de información.

- Existe también información propia que se puede integrar y manejar.

- Una vez concluido el proceso, se obtiene información estructurada.
]

.pull-right[
- La web es **desordenada**.

- Es posible que se requiera de mucho procesamiento luego de obtenido los datos.

- Se deben considerar aspectos éticos y legales.
]


---

## ¿Para que se usa el web scraping?

.pull-left[
1. Precios

1. Propiedades

1. Análisis de mercado

1. Finanzas

1. Noticias y contenido
]

.pull-right[
![Usos de web scrapping](https://miro.medium.com/max/1132/1*G_HA1qyqT9aqmLoh3bWwTw.png)
]


---

## ¿Cuál es el proceso para hacer web scraping?

1. Identificar un sitio web de interés.

1. Localizar las URLs en donde esté la información que querramos extraer.

1. Pedir la información en esos URLs al servidor para obtener el `html`.

1. Localizar la información específica que interesa guardar.

1. Guardar la información en un archivo de datos estructurado.


---

## ¿Por qué con R?

* Sistema de análisis integrado

* Luego de adquirir datos, podemos rápidamente seguir con su limpieza y análisis estadístico.

* **importar** -> manipular -> modelar -> visualizar -> comunicar

<br />
.center[
<img 
src="https://upload.wikimedia.org/wikipedia/commons/d/d4/One_Ring_Blender_Render.png" 
alt="el anillo del poder" width="33%"/>
]


---

## ¿Qué veremos en este curso?

.pull-left[
- ¿Cómo trabajar con listas en R?

- ¿Qué es una página web? ¿Cómo entender `html`?

- ¿Qué es una API?

- ¿Qué librerías podemos usar para aprovechar APIs de servicios web?

- ¿Cuáles son las consideraciones a tener en cuenta?

Será eminentemente **práctico**.
]

.pull-right[
![Mago de Oz](https://hackerchick.com/media/2019/05/wizard-of-oz-man-behind-the-curtain.jpg)
]

---
class: fullscreen, center, middle, inverse
background-image: url("images/")

## Clase 1

.huge[Aplicación práctica]


---

## ¿Qué es una página web?

.pull-left[
* Combina un protocolo de intercambio de datos ---`http`--- para el intercambio de información.

* La información intercambiada puede ser cualesquiera.

* Se intercambian mensajes individuales: el cliente envía mensaje, el servidor responde.

* Para mantener una sesión de comunicación se usan *cookies* y *encabezados*.
]

.pull-right[
![An overview of HTTP](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/fetching_a_page.png)

Fuente: [https://developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview)
]


---

## ¿Qué es una página web? Componentes

.pull-left[
* Acá se ven las capas de protocolos que componen *la web*.

* Es extensible: se pueden construir servicios unos sobre otros.

* Para nuestro interés nos interesa la parte superior: `html`, `css`, `API` y `javascript`. 
]

.pull-right[
![An overview of HTTP](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/http-layers.png)

Fuente: [https://developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview)
]


---

## ¿Qué es una página web? Componentes

.pull-left[
- `html` (*HyperText Markup Language*): provee el contenido que nos gustaría obtener.

- `css` (*Cascading Style Sheets*): controla la forma en que se muestra ese contenido.  
    Podemos usar reglas de formatos para seleccionar el contenido de la página.

- `APIs` (*Application Programming Interface*): permite pedirle a un servidor información específica de nuestro interés. 

- `javascript`: faculta a que una página web contenga programas ([¡wordle!](https://www.nytimes.com/games/wordle/index.html)).  

    Hay ocasiones que es ese programa el que pide, procesa y/o muestra los datos que nos interesa.
]

.pull-right[
![An overview of HTTP](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview/http-layers.png)

Fuente: [https://developer.mozilla.org](https://developer.mozilla.org/en-US/docs/Web/HTTP/Overview)
]


---


## ¿Cómo es una página html?

.pull-left[
<html>
<head>
    <title>Título de página</title>
</head>
<body>
  <h1 id='first'>Un encabezado</h1>
  <p>Algún texto &amp; <b>texto en negrita</b>.</p>
  <img src='./images/dog.jpg' width='100' height='100'>
</body>
</html>
]

.pull-right.font70[
```html
<!DOCTYPE html>
<html>
<head>
    <title>Título de página</title>
</head>
<body>
  <h1 id='first'>Un encabezado</h1>
  <p>Algún texto &amp; <b>texto en negrita</b>.</p>
  <img src='./images/dog.jpg' width='100' height='100'>
</body>
</html>
```
]


---

## ¿Cómo es una página html? Jerarquía

Una página web tiene una estructura jerárquica.

.pull-left[

- *Elementos*: tags como `title` o `p` que parten y terminan
  
- *Atributos*: `id` o `class`
  
- *Contenido*: Lo que queda dentro de los elementos.
]

.pull-right.font70[
```html
<!DOCTYPE html>
<html>
<head>
    <title>Título de página</title>
</head>
<body>
  <h1 id='first'>Un encabezado</h1>
  <p>Algún texto &amp; <b>texto en negrita</b>.</p>
  <img src='./images/dog.jpg' width='100' height='100'>
</body>
</html>
```
]


---

## ¿Cómo es una página html? Elementos

Elementos de `html`

.pull-left[
- Los elementos se *abren* y *cierran*, en general

  .font70[
```html
<tagname>Contenido…</tagname>
```
]

- `h#`: encabezados. Niveles de `h1` a `h6`
  
- `p`: párrafos
  
- `img`: imagen. Requiere el atributo `src` (no tiene cierre)
  
- `table`: tablas
  
- `a`: link (*anchor*). Requiere el atributo `href`
  
- `<br>`: salto de línea (no tiene cierre)

]

.pull-right.font70[
```html
<!DOCTYPE html>
<html>
<head>
    <title>Título de página</title>
</head>
<body>
  <h1 id='first'>Un encabezado</h1>
  <p>Algún texto &amp; <b>texto en negrita</b>.</p>
  <img src='./images/dog.jpg' width='100' height='100'>
</body>
</html>
```

[HTML Elements](https://www.w3schools.com/html/html_elements.asp)
]


---
class: fullscreen, center, middle

# Nuestro primer scrapping


---

## Nuestro primer scrapping: lectura contenido

Leamos la [página web](./class_1_files/mi_primer_scrapping.html) que hemos revisado.

```{r}
library(rvest)
url <- 'class_1_files/mi_primer_scrapping.html'

html <- read_html(x = url)
html
```

Capturamos el contenido de la página.


---

## Nuestro primer scrapping: extraer elementos

Capturamos el contenido de la página.

- El *body*

```{r}
html |> html_element('body')
```

- El párrafo

```{r}
html |> html_element('p')
```


---

## Nuestro primer scrapping: extraer elementos

Capturamos el contenido de la página.

- El texto del elemento identificado con `id = first`

```{r}
html |> html_element('#first') |> html_text()
```

- El link a la imágen. Atributo `src` dentro de elemento `img`

```{r}
html |> html_element('img') |> html_attr('src')
```

- Todos los atributos relacionados con la imagen.

```{r}
html |> html_element('img') |> html_attrs()
```


---

## Librerías: rvest

[Referencia](https://rvest.tidyverse.org/reference/index.html) de funciones en [rvest](https://rvest.tidyverse.org/reference/index.html) a tener en cuenta

- `xlm2::read_html()`: función exportada por rvest para leer páginas web.

- `html_attr()` `html_attrs()`: extraemos atributos

- `html_children()`: extrae elementos bajo cierto nodo

- `html_element()` `html_elements()`: extrae elementos

- `html_name()`: extrae el nombre de elementos

- `html_table()`: extrae y transforma a una data frame una tabla html

- `html_text()` `html_text2()`: extrae texto o contenido

```{r}
html |> html_element('body') |> html_children() |> html_name()
```


---

## Starwars

Recaudación y crítica según datos en [Wikipedia](https://es.wikipedia.org/wiki/Star_Wars)

```{r}
#| cache = TRUE
url <- 'https://es.wikipedia.org/wiki/Star_Wars'
html <- read_html(url)

df_tablas <- html |> 
  html_elements('table.wikitable') |>  html_table()

df_tablas |> str(1)
```

Hay 7 tablas en la página.


---

## Starwars: tablas con datos

Interesa la tabla 5 de recaudación y 6 de evaluación.

```{r}
df_tablas[[5]] |> head(3)
```

```{r}
df_tablas[[6]] |> head(3)
```


---

## Starwars: recaudación

```{r}
df_recaudacion <- df_tablas[[5]]
names(df_recaudacion) <- as.character(df_recaudacion[1, ])
  
df_recaudacion <- df_recaudacion |> 
  filter(str_detect(Película, 'Star Wars')) |> 
  mutate(across(3:5, str_remove_all, '\\.'), # Eliminar '.' en números
         across(3:5, as.integer))
```

Modifiqué los nombres de películas

```{r}
#| echo = FALSE
df_recaudacion$Película <- df_recaudacion$Película |> 
  str_remove('Star Wars: ') |> 
  str_extract('(?<= - ).*(?=\\[)|(^.*(?=:))')

df_recaudacion$Película[df_recaudacion$Película == 'The Empire Strikes Back'] <- 'Empire Strikes Back'
df_recaudacion$Película[df_recaudacion$Película == 'Rise of Skywalker'] <- 'The Rise of Skywalker'

df_recaudacion |> head(3) # Dejo fuera "The Clone wars"
```


---

## Starwars: critica

```{r}
df_critica <- df_tablas[[6]]
names(df_critica) <- as.character(df_critica[1, ])
  
df_critica <- df_critica |> 
  filter(!(Película %in% c('Película', 'Promedio'))) |> 
  mutate(across(2:7, str_extract, '\\d.?\\d'), # capturo las notas
         across(6:7, str_replace, '\\,', '\\.'), # reemplazo ',' por '.'
         across(2:5, as.integer)) # transformo strings a numeros.

df_critica |> head(4)
```


---

## Starwars: recaudación y crítica

Uniremos ambas tablas.

.font70[
```{r}
#| fig.dim=c(7, 4)
df_cyr <- left_join(df_critica, df_recaudacion, by = 'Película')

ggplot(df_cyr,
       aes(x = Total, y = General)) + 
  geom_point(size = rel(3)) +
  ggrepel::geom_label_repel(aes(label = Película)) +
  scale_x_continuous('Millones de dólares', labels = ~scales::dollar(., scale = 0.000001)) + 
  labs(title = 'Star Wars: Relación entre recaudación total y crítica (Rottentomatos)')
```
]


---

## En la próximo taller .... 

- Manejo de listas

- [purrr](https://purrr.tidyverse.org)

- dplyr, [operaciones por fila](https://dplyr.tidyverse.org/articles/rowwise.html)

    
---
class: fullscreen,left, center, middle

.huge[R se aprende usando<br> y preguntando]

*Mauricio Bucca*


---
class: inverse, middle

Presentación y código en GitHub:  
<https://github.com/caayala/web_scraping_soc40XX>  
<https://caayala.github.io/web_scraping_soc40XX>


---
class: inverse, center, middle

.huge[
¡Gracias!
]

<br>
Cristián Ayala  
<https://blog.desuc.cl/>  
<http://github.com/caayala>


```{r}
#| echo = FALSE,
#| include = FALSE

# Extraer código R
knitr::purl('class_1.Rmd',
            output = 'class_1.R',
            quiet = TRUE)
```


